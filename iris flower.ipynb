{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f464d3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iris flower has a lot of types. So we are using a ml model that can differentiate various types of iris flowers.\n",
    "#We can access this data very easily usinh psychic learn- sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris() #data is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd713fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n",
      "(30, 4)\n"
     ]
    }
   ],
   "source": [
    "#the data imported is already clean. so we now split the data into training set and test set..in order to do that we can using x and y\n",
    "X = iris.data #data of the images\n",
    "y = iris.target #the output of the data when we input it\n",
    "\n",
    "feauture_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "#starting to split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)  #the no.of data in the raining set nd the no.of data in the test set changes with test_size\n",
    "\n",
    "print(X_train.shape) #ideally we want more train data than test\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7c3c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing algorithm for model\n",
    "from sklearn.neighbors import KNeighborsClassifier #easy to use  model from scikit learn is nearest neigbors\n",
    "knn = KNeighborsClassifier(n_neighbors=3) # this n_neigbors is the parameter for \"how many data parameters do i need to observe to decide which type of flower, as there r three types of iris flowers\"\n",
    "knn.fit(X_train, y_train) # to fit the data nd use the alogorithm by givin the train data set and the y_train output\n",
    "#thus model created\n",
    "#now we have to check with the output to see how good our function is\n",
    "y_pred = knn.predict(X_test) #to predict and try out our tests so we can use the x_test data set\n",
    "#Now the cool thing that we can do is actually compare the output of y_pred predictions that our model created with the actual answers\n",
    "# we created four different data sets, right?We created the train data sets for X and Y and also the test data sets.So for the X test, we gave our new model the test data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b25d647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# the y_test data is used to compare the predictions, to do this we import metrics\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) #tells how much accurate our model is \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3d5e731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions:  ['versicolor', 'virginica']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b697d110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mlbrain.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model persistence\n",
    "# in our computers when we use ml, we dont run and train the model from the start, instead the model is already there on your phone\n",
    "from joblib import dump, load\n",
    "dump(knn, 'mlbrain.joblib')# to dump the model somewhere and it is named as \"mlbrain.joblib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2705922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions:  ['versicolor', 'virginica']\n"
     ]
    }
   ],
   "source": [
    "model = load(\"mlbrain.joblib\")\n",
    "model.predict(X_test)#predicting on the X_test data\n",
    "sample = [[3,5,4,2],[2,3,5,4]] # we r loading the model nd then just predicting\n",
    "predictions = model.predict(sample)\n",
    "pred_species = [iris.target_names[p] for p in predictions]\n",
    "print(\"predictions: \", pred_species)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
